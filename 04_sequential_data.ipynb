{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential Data Preparation for Deep Learning\n",
    "## Stanford TECH 27 Final Project - Notebook 04\n",
    "\n",
    "This notebook focuses on preparing sequential data for deep learning models (RNN, LSTM, GRU, 1D CNN) in SOC estimation.\n",
    "It builds upon the engineered features from `03_feature_engineering.ipynb`.\n",
    "\n",
    "### Goals:\n",
    "1. Load engineered features from previous notebook\n",
    "2. Prepare sequential datasets for RNN/LSTM/GRU models\n",
    "3. Create longer sequences optimized for 1D CNN models\n",
    "4. Analyze sequence characteristics and distributions\n",
    "5. Test sequential data pipeline performance\n",
    "\n",
    "### Output:\n",
    "- Sequential datasets for LSTM/RNN models\n",
    "- Sequential datasets for 1D CNN models\n",
    "- Sequence analysis and visualization\n",
    "- Performance benchmarks for sequence creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Import our custom utilities\n",
    "from data_processing_utils import (\n",
    "    load_cleaned_data, engineer_features, prepare_sequences, prepare_cnn_sequences, OUTPUT_DIR\n",
    ")\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"Pandas version: {pd.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Engineered Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load engineered features from previous notebook\n",
    "engineered_features_path = OUTPUT_DIR / 'engineered_features.csv'\n",
    "\n",
    "if engineered_features_path.exists():\n",
    "    print(\"Loading engineered features from 03_feature_engineering.ipynb...\")\n",
    "    engineered_data = pd.read_csv(engineered_features_path)\n",
    "    print(f\"Loaded engineered features: {engineered_data.shape}\")\n",
    "else:\n",
    "    print(\"Engineered features not found. Creating from cleaned data...\")\n",
    "    # Fallback: load cleaned data and engineer features\n",
    "    cleaned_data = load_cleaned_data()\n",
    "    \n",
    "    # Take a sample for testing\n",
    "    sample_batteries = cleaned_data['battery_id'].unique()[:3]  # First 3 batteries\n",
    "    sample_data = cleaned_data[cleaned_data['battery_id'].isin(sample_batteries)]\n",
    "    \n",
    "    print(f\"Creating features for {len(sample_batteries)} sample batteries...\")\n",
    "    engineered_data = engineer_features(sample_data)\n",
    "    print(f\"Created sample engineered features: {engineered_data.shape}\")\n",
    "\n",
    "print(f\"\\nEngineered data overview:\")\n",
    "print(f\"Shape: {engineered_data.shape}\")\n",
    "print(f\"SOC range: {engineered_data['SOC'].min():.3f} - {engineered_data['SOC'].max():.3f}\")\n",
    "print(f\"Unique batteries: {engineered_data['battery_id'].nunique()}\")\n",
    "\n",
    "# Show available columns\n",
    "feature_cols = [col for col in engineered_data.columns \n",
    "                if col not in ['SOC', 'battery_id', 'filename', 'test_id', 'ambient_temperature', 'time']]\n",
    "print(f\"Available features: {len(feature_cols)}\")\n",
    "print(f\"First 10 features: {feature_cols[:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Sample Data for Sequence Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a representative battery for detailed sequence analysis\n",
    "sample_battery = engineered_data['battery_id'].iloc[0]\n",
    "sample_features = engineered_data[engineered_data['battery_id'] == sample_battery].copy()\n",
    "\n",
    "print(f\"Sample battery for sequence analysis: {sample_battery}\")\n",
    "print(f\"Sample data shape: {sample_features.shape}\")\n",
    "print(f\"SOC range: {sample_features['SOC'].min():.3f} - {sample_features['SOC'].max():.3f}\")\n",
    "\n",
    "# Visualize sample data for sequence preparation\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "fig.suptitle(f'Sample Data for Sequential Analysis: {sample_battery}', fontsize=16)\n",
    "\n",
    "# SOC over time\n",
    "axes[0, 0].plot(sample_features['SOC'], 'b-', linewidth=2, alpha=0.8)\n",
    "axes[0, 0].set_title('SOC Sequence')\n",
    "axes[0, 0].set_xlabel('Time Index')\n",
    "axes[0, 0].set_ylabel('SOC')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Key features over time\n",
    "key_features = ['voltage', 'current', 'power', 'voltage_rolling_mean_10']\n",
    "for i, feature in enumerate(key_features):\n",
    "    if feature in sample_features.columns:\n",
    "        row, col = divmod(i + 1, 3)\n",
    "        if row < 2:\n",
    "            axes[row, col].plot(sample_features[feature], alpha=0.8)\n",
    "            axes[row, col].set_title(f'{feature.replace(\"_\", \" \").title()}')\n",
    "            axes[row, col].set_xlabel('Time Index')\n",
    "            axes[row, col].set_ylabel('Value')\n",
    "            axes[row, col].grid(True, alpha=0.3)\n",
    "\n",
    "# Fill any empty subplots\n",
    "for i in range(len(key_features) + 1, 6):\n",
    "    row, col = divmod(i, 3)\n",
    "    if row < 2:\n",
    "        axes[row, col].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nSequence length available: {len(sample_features)} time steps\")\n",
    "print(f\"This allows for sequences up to ~{len(sample_features)//2} timesteps with reasonable overlap\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Sequential Data for RNN/LSTM/GRU Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different sequence configurations for LSTM/RNN models\n",
    "print(\"Testing LSTM/RNN sequence preparation...\")\n",
    "\n",
    "# Define sequence configurations to test\n",
    "lstm_configs = [\n",
    "    {'length': 20, 'step': 1, 'name': 'Short overlapping (20/1)'},\n",
    "    {'length': 30, 'step': 5, 'name': 'Medium stride (30/5)'},\n",
    "    {'length': 50, 'step': 10, 'name': 'Long stride (50/10)'},\n",
    "    {'length': 40, 'step': 2, 'name': 'Balanced (40/2)'}\n",
    "]\n",
    "\n",
    "lstm_results = {}\n",
    "\n",
    "for config in lstm_configs:\n",
    "    print(f\"\\nTesting configuration: {config['name']}\")\n",
    "    \n",
    "    X_seq, y_seq, feature_names = prepare_sequences(\n",
    "        sample_features, \n",
    "        sequence_length=config['length'], \n",
    "        step=config['step']\n",
    "    )\n",
    "    \n",
    "    if len(X_seq) > 0:\n",
    "        lstm_results[config['name']] = {\n",
    "            'X_shape': X_seq.shape,\n",
    "            'y_shape': y_seq.shape,\n",
    "            'features': feature_names,\n",
    "            'config': config,\n",
    "            'memory_mb': X_seq.nbytes / 1024**2,\n",
    "            'soc_range': (y_seq.min(), y_seq.max())\n",
    "        }\n",
    "        \n",
    "        print(f\"  ‚úì Generated: X={X_seq.shape}, y={y_seq.shape}\")\n",
    "        print(f\"  Memory: {X_seq.nbytes / 1024**2:.2f} MB\")\n",
    "        print(f\"  Features: {len(feature_names)}\")\n",
    "        print(f\"  SOC range: {y_seq.min():.3f} - {y_seq.max():.3f}\")\n",
    "    else:\n",
    "        print(f\"  ‚úó No sequences generated (data too short)\")\n",
    "\n",
    "# Select best LSTM configuration\n",
    "if lstm_results:\n",
    "    # Choose config with good balance of sequences and memory usage\n",
    "    best_lstm_config = max(lstm_results.keys(), \n",
    "                          key=lambda k: lstm_results[k]['X_shape'][0] / lstm_results[k]['memory_mb'])\n",
    "    \n",
    "    print(f\"\\nüèÜ Best LSTM configuration: {best_lstm_config}\")\n",
    "    best_lstm = lstm_results[best_lstm_config]\n",
    "    print(f\"   Sequences: {best_lstm['X_shape'][0]}\")\n",
    "    print(f\"   Memory efficiency: {best_lstm['X_shape'][0] / best_lstm['memory_mb']:.1f} sequences/MB\")\n",
    "    \n",
    "    # Generate final LSTM sequences\n",
    "    X_lstm, y_lstm, lstm_features = prepare_sequences(\n",
    "        sample_features,\n",
    "        sequence_length=best_lstm['config']['length'],\n",
    "        step=best_lstm['config']['step']\n",
    "    )\n",
    "else:\n",
    "    print(\"‚ùå No valid LSTM configurations found\")\n",
    "    X_lstm, y_lstm, lstm_features = None, None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Sequential Data for 1D CNN Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test sequence configurations for 1D CNN models (longer sequences, larger steps)\n",
    "print(\"Testing 1D CNN sequence preparation...\")\n",
    "\n",
    "cnn_configs = [\n",
    "    {'length': 60, 'step': 5, 'name': 'CNN Short (60/5)'},\n",
    "    {'length': 100, 'step': 10, 'name': 'CNN Medium (100/10)'},\n",
    "    {'length': 150, 'step': 20, 'name': 'CNN Long (150/20)'},\n",
    "    {'length': 80, 'step': 8, 'name': 'CNN Balanced (80/8)'}\n",
    "]\n",
    "\n",
    "cnn_results = {}\n",
    "\n",
    "for config in cnn_configs:\n",
    "    print(f\"\\nTesting configuration: {config['name']}\")\n",
    "    \n",
    "    X_seq, y_seq, feature_names = prepare_cnn_sequences(\n",
    "        sample_features,\n",
    "        sequence_length=config['length'],\n",
    "        step=config['step']\n",
    "    )\n",
    "    \n",
    "    if len(X_seq) > 0:\n",
    "        cnn_results[config['name']] = {\n",
    "            'X_shape': X_seq.shape,\n",
    "            'y_shape': y_seq.shape,\n",
    "            'features': feature_names,\n",
    "            'config': config,\n",
    "            'memory_mb': X_seq.nbytes / 1024**2,\n",
    "            'soc_range': (y_seq.min(), y_seq.max())\n",
    "        }\n",
    "        \n",
    "        print(f\"  ‚úì Generated: X={X_seq.shape}, y={y_seq.shape}\")\n",
    "        print(f\"  Memory: {X_seq.nbytes / 1024**2:.2f} MB\")\n",
    "        print(f\"  Features: {len(feature_names)}\")\n",
    "        print(f\"  SOC range: {y_seq.min():.3f} - {y_seq.max():.3f}\")\n",
    "    else:\n",
    "        print(f\"  ‚úó No sequences generated (data too short)\")\n",
    "\n",
    "# Select best CNN configuration\n",
    "if cnn_results:\n",
    "    best_cnn_config = max(cnn_results.keys(), \n",
    "                         key=lambda k: cnn_results[k]['X_shape'][0] / cnn_results[k]['memory_mb'])\n",
    "    \n",
    "    print(f\"\\nüèÜ Best CNN configuration: {best_cnn_config}\")\n",
    "    best_cnn = cnn_results[best_cnn_config]\n",
    "    print(f\"   Sequences: {best_cnn['X_shape'][0]}\")\n",
    "    print(f\"   Memory efficiency: {best_cnn['X_shape'][0] / best_cnn['memory_mb']:.1f} sequences/MB\")\n",
    "    \n",
    "    # Generate final CNN sequences\n",
    "    X_cnn, y_cnn, cnn_features = prepare_cnn_sequences(\n",
    "        sample_features,\n",
    "        sequence_length=best_cnn['config']['length'],\n",
    "        step=best_cnn['config']['step']\n",
    "    )\n",
    "else:\n",
    "    print(\"‚ùå No valid CNN configurations found\")\n",
    "    X_cnn, y_cnn, cnn_features = None, None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Sequence Analysis and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare sequence characteristics\n",
    "print(\"=== SEQUENCE COMPARISON ===\")\n",
    "\n",
    "if X_lstm is not None:\n",
    "    print(f\"\\nLSTM Sequences:\")\n",
    "    print(f\"  Shape: {X_lstm.shape} (samples, timesteps, features)\")\n",
    "    print(f\"  Memory: {X_lstm.nbytes / 1024**2:.2f} MB\")\n",
    "    print(f\"  Target shape: {y_lstm.shape}\")\n",
    "    print(f\"  SOC coverage: {y_lstm.min():.3f} to {y_lstm.max():.3f}\")\n",
    "\n",
    "if X_cnn is not None:\n",
    "    print(f\"\\nCNN Sequences:\")\n",
    "    print(f\"  Shape: {X_cnn.shape} (samples, timesteps, features)\")\n",
    "    print(f\"  Memory: {X_cnn.nbytes / 1024**2:.2f} MB\")\n",
    "    print(f\"  Target shape: {y_cnn.shape}\")\n",
    "    print(f\"  SOC coverage: {y_cnn.min():.3f} to {y_cnn.max():.3f}\")\n",
    "\n",
    "# Visualize sequence characteristics\n",
    "if X_lstm is not None or X_cnn is not None:\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    fig.suptitle('Sequential Data Analysis', fontsize=16)\n",
    "    \n",
    "    # LSTM analysis\n",
    "    if X_lstm is not None:\n",
    "        # SOC distribution\n",
    "        axes[0, 0].hist(y_lstm * 100, bins=30, alpha=0.7, color='blue', label='LSTM')\n",
    "        axes[0, 0].set_title('LSTM Target SOC Distribution')\n",
    "        axes[0, 0].set_xlabel('SOC (%)')\n",
    "        axes[0, 0].set_ylabel('Frequency')\n",
    "        axes[0, 0].grid(True, alpha=0.3)\n",
    "        axes[0, 0].legend()\n",
    "        \n",
    "        # SOC sequence\n",
    "        axes[0, 1].plot(y_lstm * 100, alpha=0.7, color='blue')\n",
    "        axes[0, 1].set_title('LSTM SOC Sequence')\n",
    "        axes[0, 1].set_xlabel('Sequence Index')\n",
    "        axes[0, 1].set_ylabel('SOC (%)')\n",
    "        axes[0, 1].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Sample sequence visualization (first sequence, first 3 features)\n",
    "        for i in range(min(3, X_lstm.shape[2])):\n",
    "            axes[0, 2].plot(X_lstm[0, :, i], label=f'Feature {i+1}', alpha=0.8)\n",
    "        axes[0, 2].set_title('Sample LSTM Sequence Features')\n",
    "        axes[0, 2].set_xlabel('Timestep')\n",
    "        axes[0, 2].set_ylabel('Feature Value')\n",
    "        axes[0, 2].legend()\n",
    "        axes[0, 2].grid(True, alpha=0.3)\n",
    "    else:\n",
    "        for i in range(3):\n",
    "            axes[0, i].text(0.5, 0.5, 'No LSTM\\nSequences', ha='center', va='center', \n",
    "                          transform=axes[0, i].transAxes, fontsize=14)\n",
    "            axes[0, i].set_title(f'LSTM Analysis {i+1}')\n",
    "    \n",
    "    # CNN analysis\n",
    "    if X_cnn is not None:\n",
    "        # SOC distribution\n",
    "        axes[1, 0].hist(y_cnn * 100, bins=30, alpha=0.7, color='red', label='CNN')\n",
    "        axes[1, 0].set_title('CNN Target SOC Distribution')\n",
    "        axes[1, 0].set_xlabel('SOC (%)')\n",
    "        axes[1, 0].set_ylabel('Frequency')\n",
    "        axes[1, 0].grid(True, alpha=0.3)\n",
    "        axes[1, 0].legend()\n",
    "        \n",
    "        # SOC sequence\n",
    "        axes[1, 1].plot(y_cnn * 100, alpha=0.7, color='red')\n",
    "        axes[1, 1].set_title('CNN SOC Sequence')\n",
    "        axes[1, 1].set_xlabel('Sequence Index')\n",
    "        axes[1, 1].set_ylabel('SOC (%)')\n",
    "        axes[1, 1].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Sample sequence visualization\n",
    "        for i in range(min(3, X_cnn.shape[2])):\n",
    "            axes[1, 2].plot(X_cnn[0, :, i], label=f'Feature {i+1}', alpha=0.8)\n",
    "        axes[1, 2].set_title('Sample CNN Sequence Features')\n",
    "        axes[1, 2].set_xlabel('Timestep')\n",
    "        axes[1, 2].set_ylabel('Feature Value')\n",
    "        axes[1, 2].legend()\n",
    "        axes[1, 2].grid(True, alpha=0.3)\n",
    "    else:\n",
    "        for i in range(3):\n",
    "            axes[1, i].text(0.5, 0.5, 'No CNN\\nSequences', ha='center', va='center', \n",
    "                          transform=axes[1, i].transAxes, fontsize=14)\n",
    "            axes[1, i].set_title(f'CNN Analysis {i+1}')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Multi-Battery Sequence Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test sequence preparation performance across multiple batteries\n",
    "print(\"Testing sequence preparation across multiple batteries...\")\n",
    "\n",
    "unique_batteries = engineered_data['battery_id'].unique()\n",
    "n_test_batteries = min(5, len(unique_batteries))  # Test first 5 batteries\n",
    "\n",
    "print(f\"Testing {n_test_batteries} batteries for sequence preparation performance...\")\n",
    "\n",
    "lstm_performance = []\n",
    "cnn_performance = []\n",
    "total_lstm_sequences = 0\n",
    "total_cnn_sequences = 0\n",
    "\n",
    "for i, battery_id in enumerate(tqdm(unique_batteries[:n_test_batteries], desc=\"Processing batteries\")):\n",
    "    try:\n",
    "        # Get battery data\n",
    "        battery_data = engineered_data[engineered_data['battery_id'] == battery_id].copy()\n",
    "        \n",
    "        if len(battery_data) < 50:  # Skip very short sequences\n",
    "            continue\n",
    "        \n",
    "        # Time LSTM sequence preparation\n",
    "        start_time = time.time()\n",
    "        X_test_lstm, y_test_lstm, _ = prepare_sequences(\n",
    "            battery_data, \n",
    "            sequence_length=30,  # Use reasonable defaults\n",
    "            step=5\n",
    "        )\n",
    "        lstm_time = time.time() - start_time\n",
    "        \n",
    "        # Time CNN sequence preparation  \n",
    "        start_time = time.time()\n",
    "        X_test_cnn, y_test_cnn, _ = prepare_cnn_sequences(\n",
    "            battery_data, \n",
    "            sequence_length=80,  # Use reasonable defaults\n",
    "            step=10\n",
    "        )\n",
    "        cnn_time = time.time() - start_time\n",
    "        \n",
    "        # Record performance\n",
    "        if len(X_test_lstm) > 0:\n",
    "            lstm_performance.append({\n",
    "                'battery_id': battery_id,\n",
    "                'time': lstm_time,\n",
    "                'sequences': len(X_test_lstm),\n",
    "                'data_length': len(battery_data)\n",
    "            })\n",
    "            total_lstm_sequences += len(X_test_lstm)\n",
    "        \n",
    "        if len(X_test_cnn) > 0:\n",
    "            cnn_performance.append({\n",
    "                'battery_id': battery_id,\n",
    "                'time': cnn_time,\n",
    "                'sequences': len(X_test_cnn),\n",
    "                'data_length': len(battery_data)\n",
    "            })\n",
    "            total_cnn_sequences += len(X_test_cnn)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing battery {battery_id}: {e}\")\n",
    "        continue\n",
    "\n",
    "# Performance summary\n",
    "if lstm_performance or cnn_performance:\n",
    "    print(f\"\\n=== PERFORMANCE RESULTS ===\")\n",
    "    print(f\"Tested batteries: {n_test_batteries}\")\n",
    "    \n",
    "    if lstm_performance:\n",
    "        avg_lstm_time = np.mean([p['time'] for p in lstm_performance])\n",
    "        avg_lstm_sequences = np.mean([p['sequences'] for p in lstm_performance])\n",
    "        print(f\"\\nLSTM Performance:\")\n",
    "        print(f\"  Successful batteries: {len(lstm_performance)}\")\n",
    "        print(f\"  Average time per battery: {avg_lstm_time:.3f} seconds\")\n",
    "        print(f\"  Average sequences per battery: {avg_lstm_sequences:.1f}\")\n",
    "        print(f\"  Total sequences generated: {total_lstm_sequences}\")\n",
    "        print(f\"  Sequences per second: {total_lstm_sequences / sum(p['time'] for p in lstm_performance):.1f}\")\n",
    "        \n",
    "    if cnn_performance:\n",
    "        avg_cnn_time = np.mean([p['time'] for p in cnn_performance])\n",
    "        avg_cnn_sequences = np.mean([p['sequences'] for p in cnn_performance])\n",
    "        print(f\"\\nCNN Performance:\")\n",
    "        print(f\"  Successful batteries: {len(cnn_performance)}\")\n",
    "        print(f\"  Average time per battery: {avg_cnn_time:.3f} seconds\")\n",
    "        print(f\"  Average sequences per battery: {avg_cnn_sequences:.1f}\")\n",
    "        print(f\"  Total sequences generated: {total_cnn_sequences}\")\n",
    "        print(f\"  Sequences per second: {total_cnn_sequences / sum(p['time'] for p in cnn_performance):.1f}\")\n",
    "        \n",
    "    # Estimate full dataset processing time\n",
    "    total_batteries = len(unique_batteries)\n",
    "    if lstm_performance:\n",
    "        estimated_lstm_time = avg_lstm_time * total_batteries / 60\n",
    "        print(f\"\\nEstimated LSTM processing time for {total_batteries} batteries: {estimated_lstm_time:.1f} minutes\")\n",
    "        \n",
    "    if cnn_performance:\n",
    "        estimated_cnn_time = avg_cnn_time * total_batteries / 60\n",
    "        print(f\"Estimated CNN processing time for {total_batteries} batteries: {estimated_cnn_time:.1f} minutes\")\n",
    "        \n",
    "else:\n",
    "    print(\"‚ùå No batteries processed successfully for performance testing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save Sequential Data and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save sample sequence data and configuration\n",
    "sequence_data = {}\n",
    "saved_files = []\n",
    "\n",
    "# Save LSTM sequence data\n",
    "if X_lstm is not None and y_lstm is not None:\n",
    "    sequence_data['lstm'] = {\n",
    "        'X': X_lstm,\n",
    "        'y': y_lstm,\n",
    "        'features': lstm_features,\n",
    "        'config': lstm_results[best_lstm_config] if 'best_lstm_config' in locals() else None,\n",
    "        'battery_id': sample_battery\n",
    "    }\n",
    "    print(f\"‚úì Prepared LSTM sample data: {X_lstm.shape}\")\n",
    "\n",
    "# Save CNN sequence data\n",
    "if X_cnn is not None and y_cnn is not None:\n",
    "    sequence_data['cnn'] = {\n",
    "        'X': X_cnn,\n",
    "        'y': y_cnn,\n",
    "        'features': cnn_features,\n",
    "        'config': cnn_results[best_cnn_config] if 'best_cnn_config' in locals() else None,\n",
    "        'battery_id': sample_battery\n",
    "    }\n",
    "    print(f\"‚úì Prepared CNN sample data: {X_cnn.shape}\")\n",
    "\n",
    "# Save sample sequence data\n",
    "if sequence_data:\n",
    "    sequence_path = OUTPUT_DIR / 'sample_sequence_data.pkl'\n",
    "    with open(sequence_path, 'wb') as f:\n",
    "        pickle.dump(sequence_data, f)\n",
    "    print(f\"Saved sample sequence data to {sequence_path}\")\n",
    "    saved_files.append(str(sequence_path))\n",
    "\n",
    "# Save comprehensive sequence preparation metadata\n",
    "sequence_metadata = {\n",
    "    'sample_battery': sample_battery,\n",
    "    'lstm_configs_tested': lstm_results if 'lstm_results' in locals() else {},\n",
    "    'cnn_configs_tested': cnn_results if 'cnn_results' in locals() else {},\n",
    "    'best_configs': {\n",
    "        'lstm': {\n",
    "            'name': best_lstm_config if 'best_lstm_config' in locals() else None,\n",
    "            'config': lstm_results[best_lstm_config]['config'] if 'best_lstm_config' in locals() else None\n",
    "        },\n",
    "        'cnn': {\n",
    "            'name': best_cnn_config if 'best_cnn_config' in locals() else None,\n",
    "            'config': cnn_results[best_cnn_config]['config'] if 'best_cnn_config' in locals() else None\n",
    "        }\n",
    "    },\n",
    "    'performance_stats': {\n",
    "        'lstm_avg_time': np.mean([p['time'] for p in lstm_performance]) if lstm_performance else None,\n",
    "        'cnn_avg_time': np.mean([p['time'] for p in cnn_performance]) if cnn_performance else None,\n",
    "        'total_lstm_sequences': total_lstm_sequences if 'total_lstm_sequences' in locals() else 0,\n",
    "        'total_cnn_sequences': total_cnn_sequences if 'total_cnn_sequences' in locals() else 0,\n",
    "        'batteries_tested': n_test_batteries if 'n_test_batteries' in locals() else 0\n",
    "    },\n",
    "    'recommended_configs': {\n",
    "        'lstm': {\n",
    "            'sequence_length': lstm_results[best_lstm_config]['config']['length'] if 'best_lstm_config' in locals() else 30,\n",
    "            'step': lstm_results[best_lstm_config]['config']['step'] if 'best_lstm_config' in locals() else 5,\n",
    "            'features': lstm_features if 'lstm_features' in locals() else []\n",
    "        },\n",
    "        'cnn': {\n",
    "            'sequence_length': cnn_results[best_cnn_config]['config']['length'] if 'best_cnn_config' in locals() else 80,\n",
    "            'step': cnn_results[best_cnn_config]['config']['step'] if 'best_cnn_config' in locals() else 10,\n",
    "            'features': cnn_features if 'cnn_features' in locals() else []\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "metadata_path = OUTPUT_DIR / 'sequence_preparation_metadata.pkl'\n",
    "with open(metadata_path, 'wb') as f:\n",
    "    pickle.dump(sequence_metadata, f)\n",
    "print(f\"Saved sequence preparation metadata to {metadata_path}\")\n",
    "saved_files.append(str(metadata_path))\n",
    "\n",
    "print(f\"\\n‚úÖ Sequential data preparation complete!\")\n",
    "print(f\"Files saved: {len(saved_files)}\")\n",
    "for file_path in saved_files:\n",
    "    file_size = Path(file_path).stat().st_size / 1024**2\n",
    "    print(f\"  {Path(file_path).name}: {file_size:.2f} MB\")\n",
    "\n",
    "print(f\"\\nüöÄ Ready for final data processing and splits (Notebook 05)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook has successfully:\n",
    "\n",
    "### ‚úÖ Completed Tasks:\n",
    "1. **Data Loading**: Loaded engineered features from `03_feature_engineering.ipynb`\n",
    "2. **LSTM/RNN Sequences**: Created sequential datasets optimized for recurrent neural networks\n",
    "   - Tested multiple sequence lengths and step sizes\n",
    "   - Optimized configurations for temporal dependencies\n",
    "   - Selected best performing configurations\n",
    "3. **1D CNN Sequences**: Prepared longer sequences for convolutional approaches\n",
    "   - Longer sequences for pattern detection\n",
    "   - Larger step sizes for computational efficiency\n",
    "   - Memory-efficient configurations\n",
    "4. **Sequence Analysis**: Comprehensive analysis of sequence characteristics\n",
    "   - SOC distribution analysis across sequences\n",
    "   - Feature patterns within sequences\n",
    "   - Memory usage optimization\n",
    "5. **Performance Testing**: Benchmarked sequence preparation pipeline across multiple batteries\n",
    "\n",
    "### üìä Key Results:\n",
    "- **LSTM Sequences**: Optimized for temporal dependencies with configurable overlap\n",
    "- **CNN Sequences**: Longer sequences for spatial-temporal pattern recognition\n",
    "- **Feature Selection**: Comprehensive feature set from engineered data\n",
    "- **Scalability**: Efficient pipeline with performance metrics\n",
    "\n",
    "### üîß Recommended Configurations:\n",
    "Based on testing, the optimal configurations are saved in the metadata file:\n",
    "- **LSTM/RNN**: Balanced sequence length and step size for temporal modeling\n",
    "- **1D CNN**: Longer sequences with efficient step sizes for pattern recognition\n",
    "- **Features**: Full engineered feature set for comprehensive modeling\n",
    "\n",
    "### üìÅ Output Files:\n",
    "- `processed_data/sample_sequence_data.pkl`: Sample sequential datasets for both LSTM and CNN\n",
    "- `processed_data/sequence_preparation_metadata.pkl`: Configuration details and performance metrics\n",
    "\n",
    "### üöÄ Next Steps:\n",
    "1. **Notebook 05**: Final Data Processing and Train/Val/Test Splits\n",
    "2. Model training notebooks will load these optimized sequence configurations\n",
    "\n",
    "The sequential datasets are now ready for deep learning model training with:\n",
    "- Proper temporal structure preserved for SOC estimation\n",
    "- Optimized configurations for different model architectures\n",
    "- Comprehensive performance benchmarks for scaling\n",
    "- Memory-efficient sequence generation pipeline"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}